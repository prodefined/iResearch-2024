{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to original notebook\n",
    "*note: this notebook is missing a signifcant amount of code an will not run on it's own*\n",
    "https://colab.research.google.com/github/idiap/w2v2-air-traffic/blob/main/src/eval_xlsr_atc_model.ipynb#scrollTo=7ddc6ef1-5a73-40c8-8199-deb3e94bdb2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCTC, Wav2Vec2Processor, AutoProcessor, pipeline\n",
    "import torchaudio.functional as F\n",
    "\n",
    "if os.name == 'posix':\n",
    "    # Linux\n",
    "    os.chdir('/home/rodoggx/Documents/iResearch-2024/DATA')\n",
    "elif os.name == 'nt':\n",
    "    # Windows\n",
    "    os.chdir('C:/Users/rowan/OneDrive/Desktop/code/iResearch-2024/DATA')\n",
    "else:\n",
    "    print(\"Unknown operating system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LKPR_RUZYNE_Radar_120_520MHz_20201026_205056.wav</td>\n",
       "      <td>[Hotel Delta Charlie your're at the CTR freque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LKPR_RUZYNE_Tower_134_560MHz_20201025_101021.wav</td>\n",
       "      <td>[Singapore Three Four Six contact apron one tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZIB_STEFANIK_Tower_118_3MHz_20210505_145115.wav</td>\n",
       "      <td>[Hotel India Victor after whiskey two join wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LKTB_BRNO_Approach-Radar_127_350MHz_20201028_1...</td>\n",
       "      <td>[Sydney tower [#callsign]Rex[/#callsign] [#cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LKPR_RUZYNE_Tower_134_560MHz_20201025_204809.wav</td>\n",
       "      <td>[taxi holding point three one via Foxtrot cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210502_055020.wav</td>\n",
       "      <td>[one six right cleared to land Jetex Seven Fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>LSZH_ZURICH_Tower_118_1MHz_20210414_101150.wav</td>\n",
       "      <td>[Jetstar Four Zero Nine approved route to brav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210505_124859.wav</td>\n",
       "      <td>[Hotel Hotel Bravo seven thousand feet, Hotel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210501_090436.wav</td>\n",
       "      <td>[Emirates Eight Eight wind zero four zero thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>LSZB_BERN_Tower_121_0MHz_20210413_112156.wav</td>\n",
       "      <td>[Hotel Hotel Golf next left via delta to blue ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 audio  \\\n",
       "0     LKPR_RUZYNE_Radar_120_520MHz_20201026_205056.wav   \n",
       "1     LKPR_RUZYNE_Tower_134_560MHz_20201025_101021.wav   \n",
       "2     LZIB_STEFANIK_Tower_118_3MHz_20210505_145115.wav   \n",
       "3    LKTB_BRNO_Approach-Radar_127_350MHz_20201028_1...   \n",
       "4     LKPR_RUZYNE_Tower_134_560MHz_20201025_204809.wav   \n",
       "..                                                 ...   \n",
       "555     YSSY_SYDNEY_Tower_120_5MHz_20210502_055020.wav   \n",
       "556     LSZH_ZURICH_Tower_118_1MHz_20210414_101150.wav   \n",
       "557     YSSY_SYDNEY_Tower_120_5MHz_20210505_124859.wav   \n",
       "558     YSSY_SYDNEY_Tower_120_5MHz_20210501_090436.wav   \n",
       "559       LSZB_BERN_Tower_121_0MHz_20210413_112156.wav   \n",
       "\n",
       "                                           transcripts  \n",
       "0    [Hotel Delta Charlie your're at the CTR freque...  \n",
       "1    [Singapore Three Four Six contact apron one tw...  \n",
       "2    [Hotel India Victor after whiskey two join wid...  \n",
       "3    [Sydney tower [#callsign]Rex[/#callsign] [#cal...  \n",
       "4    [taxi holding point three one via Foxtrot cros...  \n",
       "..                                                 ...  \n",
       "555  [one six right cleared to land Jetex Seven Fou...  \n",
       "556  [Jetstar Four Zero Nine approved route to brav...  \n",
       "557  [Hotel Hotel Bravo seven thousand feet, Hotel ...  \n",
       "558  [Emirates Eight Eight wind zero four zero thre...  \n",
       "559  [Hotel Hotel Golf next left via delta to blue ...  \n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioFiles = [f for f in os.listdir() if f.endswith('.wav')]\n",
    "xmlFiles = []\n",
    "for i in range(len(audioFiles)):\n",
    "\txmlFiles.append(audioFiles[i].replace('.wav', '.xml'))\n",
    "\n",
    "transcripts = []\n",
    "\n",
    "datasetDict = {\n",
    "\t'audio': audioFiles,\n",
    "\t'transcripts': []\n",
    "}\n",
    "\n",
    "for i in range(len(xmlFiles)):\n",
    "\twith open(xmlFiles[i], 'r', encoding='utf-8') as file:\n",
    "\t\tdata = file.read()\n",
    "\n",
    "\tBs_data = BeautifulSoup(data, \"xml\")\n",
    "\tb_unique = Bs_data.find_all('text')\n",
    "\tfor j in b_unique:\n",
    "\t\ttranscripts.append(j.text)\n",
    "\tdatasetDict['transcripts'].append(transcripts)\n",
    "\ttranscripts = []\n",
    "\n",
    "df = pd.DataFrame(datasetDict)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\rowan\\OneDrive\\Desktop\\code\\iResearch-2024\\venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Upguards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=False, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not load the `decoder` for Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim. Defaulting to raw CTC. Error: No module named 'kenlm'\n",
      "Try to install `kenlm`: `pip install kenlm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm seven three whiskey maintain present heading for vectoring ils approach runway two four and rehe our speed no below two six zero knots\n",
      "[\"Hotel Delta Charlie your're at the CTR frequency change approved bye bye\"]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim\")\n",
    "\n",
    "result = pipe(df['audio'][0])\n",
    "print(result['text'])\n",
    "print(df['transcripts'][0])\n",
    "# print(result['text'] == df['transcripts'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
