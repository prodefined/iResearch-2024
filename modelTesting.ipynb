{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to original notebook\n",
    "*note: this notebook is missing a signifcant amount of code an will not run on it's own*\n",
    "https://colab.research.google.com/github/idiap/w2v2-air-traffic/blob/main/src/eval_xlsr_atc_model.ipynb#scrollTo=7ddc6ef1-5a73-40c8-8199-deb3e94bdb2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCTC, Wav2Vec2Processor, AutoProcessor, pipeline\n",
    "import torchaudio.functional as F\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "if os.name == 'posix':\n",
    "    # Linux\n",
    "    os.chdir('/home/rodoggx/Documents/iResearch-2024/DATA')\n",
    "elif os.name == 'nt':\n",
    "    # Windows\n",
    "    os.chdir('C:/Users/rowan/OneDrive/Desktop/code/iResearch-2024/DATA')\n",
    "else:\n",
    "    print(\"Unknown operating system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LKPR_RUZYNE_Radar_120_520MHz_20201026_205056.wav</td>\n",
       "      <td>[KLM Seven Three Whiskey maintain present head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LKPR_RUZYNE_Tower_134_560MHz_20201025_101021.wav</td>\n",
       "      <td>[Ryan Air Seven Romeo Mike route reaching and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZIB_STEFANIK_Tower_118_3MHz_20210505_145115.wav</td>\n",
       "      <td>[Topjet Four Zero Two via delta foxtrot ten th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LKTB_BRNO_Approach-Radar_127_350MHz_20201028_1...</td>\n",
       "      <td>[Oscar Kilo Delta Sierra India turn left headi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LKPR_RUZYNE_Tower_134_560MHz_20201025_204809.wav</td>\n",
       "      <td>[Ruzyne tower Trans Europe Four Two One [Ne Cz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210502_055020.wav</td>\n",
       "      <td>[[#unnamed]tower[/#unnamed] [#unnamed]good[/#u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>LSZH_ZURICH_Tower_118_1MHz_20210414_101150.wav</td>\n",
       "      <td>[Hotel Delta Lima contact apron one two one de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210505_124859.wav</td>\n",
       "      <td>[[#command]cleared[/#command] [#command]to[/#c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210501_090436.wav</td>\n",
       "      <td>[Sydney tower evening Qantas Seventy Seven Zer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>LSZB_BERN_Tower_121_0MHz_20210413_112156.wav</td>\n",
       "      <td>[Hotel Victor Bravo roger behind traffic on fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 audio  \\\n",
       "0     LKPR_RUZYNE_Radar_120_520MHz_20201026_205056.wav   \n",
       "1     LKPR_RUZYNE_Tower_134_560MHz_20201025_101021.wav   \n",
       "2     LZIB_STEFANIK_Tower_118_3MHz_20210505_145115.wav   \n",
       "3    LKTB_BRNO_Approach-Radar_127_350MHz_20201028_1...   \n",
       "4     LKPR_RUZYNE_Tower_134_560MHz_20201025_204809.wav   \n",
       "..                                                 ...   \n",
       "555     YSSY_SYDNEY_Tower_120_5MHz_20210502_055020.wav   \n",
       "556     LSZH_ZURICH_Tower_118_1MHz_20210414_101150.wav   \n",
       "557     YSSY_SYDNEY_Tower_120_5MHz_20210505_124859.wav   \n",
       "558     YSSY_SYDNEY_Tower_120_5MHz_20210501_090436.wav   \n",
       "559       LSZB_BERN_Tower_121_0MHz_20210413_112156.wav   \n",
       "\n",
       "                                           transcripts  \n",
       "0    [KLM Seven Three Whiskey maintain present head...  \n",
       "1    [Ryan Air Seven Romeo Mike route reaching and ...  \n",
       "2    [Topjet Four Zero Two via delta foxtrot ten th...  \n",
       "3    [Oscar Kilo Delta Sierra India turn left headi...  \n",
       "4    [Ruzyne tower Trans Europe Four Two One [Ne Cz...  \n",
       "..                                                 ...  \n",
       "555  [[#unnamed]tower[/#unnamed] [#unnamed]good[/#u...  \n",
       "556  [Hotel Delta Lima contact apron one two one de...  \n",
       "557  [[#command]cleared[/#command] [#command]to[/#c...  \n",
       "558  [Sydney tower evening Qantas Seventy Seven Zer...  \n",
       "559  [Hotel Victor Bravo roger behind traffic on fi...  \n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioFiles = [f for f in os.listdir() if f.endswith('.wav')]\n",
    "xmlFiles = []\n",
    "for i in range(len(audioFiles)):\n",
    "\txmlFiles.append(audioFiles[i].replace('.wav', '.xml'))\n",
    "\n",
    "transcripts = []\n",
    "\n",
    "datasetDict = {\n",
    "\t'audio': audioFiles,\n",
    "\t'transcripts': []\n",
    "}\n",
    "\n",
    "for i in range(len(xmlFiles)):\n",
    "\twith open(xmlFiles[i], 'r', encoding='utf-8') as file:\n",
    "\t\tdata = file.read()\n",
    "\n",
    "\tBs_data = BeautifulSoup(data, \"xml\")\n",
    "\tb_unique = Bs_data.find_all('text')\n",
    "\tfor j in b_unique:\n",
    "\t\ttranscripts.append(j.text)\n",
    "\tdatasetDict['transcripts'].append(transcripts)\n",
    "\ttranscripts = []\n",
    "\n",
    "df = pd.DataFrame(datasetDict)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\rowan\\OneDrive\\Desktop\\code\\iResearch-2024\\venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Upguards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=False, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not load the `decoder` for Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim. Defaulting to raw CTC. Error: No module named 'kenlm'\n",
      "Try to install `kenlm`: `pip install kenlm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm seven three whiskey maintain present heading for vectoring ils approach runway two four and rehe our speed no below two six zero knots\n",
      "['KLM Seven Three Whiskey maintain present heading for vectoring for ILS approach runway two four and reduce your speed now below two six zero knots']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')},\nInput predictions: ['lm seven three whiskey maintain present heading for vectoring ils approach runway two four and rehe our speed no below two six zero knots'],\nInput references: [['KLM Seven Three Whiskey maintain present heading for vectoring for ILS approach runway two four and reduce your speed now below two six zero knots']]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranscripts\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      9\u001b[0m wer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m wer_score \u001b[38;5;241m=\u001b[39m \u001b[43mwer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranscripts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(wer_score)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(result['text'] == df['transcripts'][0])\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/iResearch-2024/venv/lib/python3.11/site-packages/evaluate/module.py:455\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/iResearch-2024/venv/lib/python3.11/site-packages/evaluate/module.py:546\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions and/or references don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the expected format.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummarize_if_long_list(predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput references: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummarize_if_long_list(references)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m     )\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')},\nInput predictions: ['lm seven three whiskey maintain present heading for vectoring ils approach runway two four and rehe our speed no below two six zero knots'],\nInput references: [['KLM Seven Three Whiskey maintain present heading for vectoring for ILS approach runway two four and reduce your speed now below two six zero knots']]"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim\")\n",
    "\n",
    "result = pipe(df['audio'][0])\n",
    "print(result['text'])\n",
    "print(df['transcripts'][0])\n",
    "\n",
    "wer = load('wer')\n",
    "wer_score = wer.compute(predictions=[result['text']], references=[df['transcripts'][0]])\n",
    "print(wer_score)\n",
    "# print(result['text'] == df['transcripts'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
