{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to original notebook\n",
    "*note: this notebook is missing a signifcant amount of code an will not run on it's own*\n",
    "https://colab.research.google.com/github/idiap/w2v2-air-traffic/blob/main/src/eval_xlsr_atc_model.ipynb#scrollTo=7ddc6ef1-5a73-40c8-8199-deb3e94bdb2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCTC, Wav2Vec2Processor, AutoProcessor, pipeline\n",
    "import torchaudio.functional as F\n",
    "\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "os.chdir('C:/Users/rowan/OneDrive/Desktop/code/iResearch-2024/DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>transcripts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LKPR_RUZYNE_Radar_120_520MHz_20201025_091112.wav</td>\n",
       "      <td>[Oscar Kilo Papa Mike Bravo descend flight lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LKPR_RUZYNE_Radar_120_520MHz_20201025_120512.wav</td>\n",
       "      <td>[Oscar Kilo Kilo Echo Alfa Praha Radar identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LKPR_RUZYNE_Radar_120_520MHz_20201025_121325.wav</td>\n",
       "      <td>[Ryanair Seven Three Alpha Hotel turn left hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LKPR_RUZYNE_Radar_120_520MHz_20201025_130407.wav</td>\n",
       "      <td>[Oscar Kilo Kilo Uniform November proceed dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LKPR_RUZYNE_Radar_120_520MHz_20201025_140929.wav</td>\n",
       "      <td>[Eurowings Seven Alfa Bravo turn right heading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210505_204538.wav</td>\n",
       "      <td>[[#unnamed]tower[/#unnamed] [#unnamed]good[/#u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210505_214612.wav</td>\n",
       "      <td>[Sydney tower Srilankan Six Zero Six back with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210505_224723.wav</td>\n",
       "      <td>[[#value]runway[/#value] [#value]one[/#value] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210505_233332.wav</td>\n",
       "      <td>[Sydney tower good day China Eastern Seven Fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>YSSY_SYDNEY_Tower_120_5MHz_20210505_234913.wav</td>\n",
       "      <td>[runway one six right cleared to land Malaysia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                audio  \\\n",
       "0    LKPR_RUZYNE_Radar_120_520MHz_20201025_091112.wav   \n",
       "1    LKPR_RUZYNE_Radar_120_520MHz_20201025_120512.wav   \n",
       "2    LKPR_RUZYNE_Radar_120_520MHz_20201025_121325.wav   \n",
       "3    LKPR_RUZYNE_Radar_120_520MHz_20201025_130407.wav   \n",
       "4    LKPR_RUZYNE_Radar_120_520MHz_20201025_140929.wav   \n",
       "..                                                ...   \n",
       "555    YSSY_SYDNEY_Tower_120_5MHz_20210505_204538.wav   \n",
       "556    YSSY_SYDNEY_Tower_120_5MHz_20210505_214612.wav   \n",
       "557    YSSY_SYDNEY_Tower_120_5MHz_20210505_224723.wav   \n",
       "558    YSSY_SYDNEY_Tower_120_5MHz_20210505_233332.wav   \n",
       "559    YSSY_SYDNEY_Tower_120_5MHz_20210505_234913.wav   \n",
       "\n",
       "                                           transcripts  \n",
       "0    [Oscar Kilo Papa Mike Bravo descend flight lev...  \n",
       "1    [Oscar Kilo Kilo Echo Alfa Praha Radar identif...  \n",
       "2    [Ryanair Seven Three Alpha Hotel turn left hea...  \n",
       "3    [Oscar Kilo Kilo Uniform November proceed dire...  \n",
       "4    [Eurowings Seven Alfa Bravo turn right heading...  \n",
       "..                                                 ...  \n",
       "555  [[#unnamed]tower[/#unnamed] [#unnamed]good[/#u...  \n",
       "556  [Sydney tower Srilankan Six Zero Six back with...  \n",
       "557  [[#value]runway[/#value] [#value]one[/#value] ...  \n",
       "558  [Sydney tower good day China Eastern Seven Fiv...  \n",
       "559  [runway one six right cleared to land Malaysia...  \n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioFiles = [f for f in os.listdir() if f.endswith('.wav')]\n",
    "xmlFiles = [f for f in os.listdir() if f.endswith('.xml')]\n",
    "\n",
    "transcripts = []\n",
    "\n",
    "datasetDict = {\n",
    "\t'audio': audioFiles,\n",
    "\t'transcripts': []\n",
    "}\n",
    "\n",
    "for i in range(len(xmlFiles)):\n",
    "\twith open(xmlFiles[i], 'r', encoding='utf-8') as file:\n",
    "\t\tdata = file.read()\n",
    "\n",
    "\tBs_data = BeautifulSoup(data, \"xml\")\n",
    "\tb_unique = Bs_data.find_all('text')\n",
    "\tfor j in b_unique:\n",
    "\t\ttranscripts.append(j.text)\n",
    "\tdatasetDict['transcripts'].append(transcripts)\n",
    "\ttranscripts = []\n",
    "\n",
    "df = pd.DataFrame(datasetDict)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\rowan\\OneDrive\\Desktop\\code\\iResearch-2024\\venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Upguards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=False, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not load the `decoder` for Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim. Defaulting to raw CTC. Error: No module named 'kenlm'\n",
      "Try to install `kenlm`: `pip install kenlm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim\")\n",
    "\n",
    "# result = pipe(df['audio'][0])\n",
    "# result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
